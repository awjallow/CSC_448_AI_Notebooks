{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ff3c37",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/awjallow/CSC_448_AI_Notebooks/blob/main/csc_448_assignment_4_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "7ec6b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and pip installations (if needed)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d1d85",
   "metadata": {},
   "source": [
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "1969bee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal length</th>\n",
       "      <th>Sepal width</th>\n",
       "      <th>Petal length</th>\n",
       "      <th>Petal width</th>\n",
       "      <th>Class label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sepal length  Sepal width  Petal length  Petal width  Class label\n",
       "0            5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1            4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2            4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3            4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4            5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5            5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6            4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7            5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8            4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9            4.9          3.1           1.5          0.1  Iris-setosa\n",
       "10           5.4          3.7           1.5          0.2  Iris-setosa\n",
       "11           4.8          3.4           1.6          0.2  Iris-setosa\n",
       "12           4.8          3.0           1.4          0.1  Iris-setosa\n",
       "13           4.3          3.0           1.1          0.1  Iris-setosa\n",
       "14           5.8          4.0           1.2          0.2  Iris-setosa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 150 \n",
      "\n",
      "Classes:  ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica'] \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Sepal length  150 non-null    float64\n",
      " 1   Sepal width   150 non-null    float64\n",
      " 2   Petal length  150 non-null    float64\n",
      " 3   Petal width   150 non-null    float64\n",
      " 4   Class label   150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header = None)\n",
    "df.columns = ['Sepal length', 'Sepal width', 'Petal length', 'Petal width', 'Class label']\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "display(df.head(15))\n",
    "\n",
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "print(\"Number of datapoints:\", len(df), \"\\n\")\n",
    "\n",
    "IA = df.iloc[:,:].values\n",
    "IC = np.unique(IA[:,4])\n",
    "print(\"Classes: \", IC, \"\\n\")\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75555292",
   "metadata": {},
   "source": [
    "# About the dataset\n",
    "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?\n",
    "\n",
    "Answer: <br>\n",
    "The iris dataset consists of information about attributes of three different plant species, namely, setosa,  versicolor, and virginica. <br>\n",
    "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] <br>\n",
    "Labels: ['setosa' 'versicolor' 'virginica'] <br>\n",
    "The class labels are the last column values of the dataset so Class labels: [0 1 2] (mapped from ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df83f97",
   "metadata": {},
   "source": [
    "# Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "839ff10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# print(X)\n",
    "# print(y)\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "# print(\"X_train:\", (X_train))\n",
    "# print(\"X_test:\", (X_test))\n",
    "# print(\"y_train:\", (y_train))\n",
    "# print(\"y_test:\", (y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa0383",
   "metadata": {},
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "eea3e2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities prediction on sample datapoint [4, 3, 2, 1]: [9.41540426e-01 5.84508886e-02 8.68586296e-06]\n",
      "\n",
      "Logistic regression score: 1.00\n",
      "The score measures the mean accuracy on the given test data and labels.\n",
      "\n",
      "Coefficents: [[-0.42671896  0.97265658 -2.44465216 -1.03186382]\n",
      " [ 0.51310009 -0.22373863 -0.21510023 -0.85159643]\n",
      " [-0.08638113 -0.74891795  2.65975239  1.88346025]]\n",
      "\n",
      "Intercepts: [  9.50104298   1.91225076 -11.41329374]\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sample_dp = [4,3,2,1]\n",
    "print(\"Probabilities prediction on sample datapoint {}:\".format(sample_dp), (log_reg.predict_proba([sample_dp])[0]))\n",
    "print()\n",
    "\n",
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "print(\"Logistic regression score: %.2f\" % log_reg.score(X_test, y_test))\n",
    "print(\"The score measures the mean accuracy on the given test data and labels.\")\n",
    "print()\n",
    "\n",
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "coefficients, intercepts = log_reg.coef_, log_reg.intercept_\n",
    "print(\"Coefficents:\", coefficients)\n",
    "print()\n",
    "print(\"Intercepts:\", intercepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e3246a",
   "metadata": {},
   "source": [
    "# Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "d0ccb02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities prediction on sample datapoint [4, 3, 2, 1]: [0.76356495 0.19248012 0.04395493]\n",
      "\n",
      "Linear SVM score: 1.00\n",
      "The score measures the mean accuracy on the given test data and labels.\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "svm_linear = SVC(kernel=\"linear\", probability=True)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sample_dp = [4,3,2,1]\n",
    "print(\"Probabilities prediction on sample datapoint {}:\".format(sample_dp), (svm_linear.predict_proba([sample_dp])[0]))\n",
    "print()\n",
    "\n",
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "print(\"Linear SVM score: %.2f\" % svm_linear.score(X_test, y_test))\n",
    "print(\"The score measures the mean accuracy on the given test data and labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57804b5",
   "metadata": {},
   "source": [
    "# Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "6d681c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities prediction on sample datapoint [4, 3, 2, 1]: [9.81912099e-01 1.80879006e-02 3.94841795e-21]\n",
      "\n",
      "Neural Network (MLP Classifier) with (lbfgs solver) score: 0.93\n",
      "The score measures the mean accuracy on the given test data and labels.\n",
      "\n",
      "Neural Network (MLP Classifier) with (SGD solver) score: 1.00\n",
      "\n",
      "Score varies depending on the parameters passed into MLPClassifier class, such as lbfgs or SDG solver. The NN with SDG solver yields higher score in this test data and labels\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "nn_mlp = MLPClassifier(solver=\"lbfgs\", alpha=1e-5, hidden_layer_sizes=(135), random_state=1, max_iter=600)\n",
    "nn_mlp.fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sample_dp = [4,3,2,1]\n",
    "print(\"Probabilities prediction on sample datapoint {}:\".format(sample_dp), (nn_mlp.predict_proba([sample_dp])[0]))\n",
    "print()\n",
    "\n",
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "print(\"Neural Network (MLP Classifier) with (lbfgs solver) score: %.2f\" % nn_mlp.score(X_test, y_test))\n",
    "print(\"The score measures the mean accuracy on the given test data and labels.\")\n",
    "print()\n",
    "\n",
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "nn_mlp_2 = MLPClassifier(solver=\"sgd\", alpha=1e-5, hidden_layer_sizes=(135), random_state=1, max_iter=1200)\n",
    "nn_mlp_2.fit(X_train, y_train)\n",
    "print(\"Neural Network (MLP Classifier) with (SGD solver) score: %.2f\" % nn_mlp_2.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "print(\"Score varies depending on the parameters passed into MLPClassifier class, such as lbfgs or SDG solver.\",\n",
    "      \"The NN with SDG solver yields higher score in this test data and labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857edc7d",
   "metadata": {},
   "source": [
    "# Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "fff23031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities prediction on sample datapoint [4, 3, 2, 1]: [1. 0. 0.]\n",
      "\n",
      "K-Nearest Neighbors score: 1.00\n",
      "The score measures the mean accuracy on the given test data and labels.\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "sample_dp = [4,3,2,1]\n",
    "print(\"Probabilities prediction on sample datapoint {}:\".format(sample_dp), (knn.predict_proba([sample_dp])[0]))\n",
    "print()\n",
    "\n",
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "print(\"K-Nearest Neighbors score: %.2f\" % knn.score(X_test, y_test))\n",
    "print(\"The score measures the mean accuracy on the given test data and labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3fa8f",
   "metadata": {},
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "\n",
    "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5fc3c",
   "metadata": {},
   "source": [
    "Conclusions & Takeways: <br>\n",
    "All models, except for the Neural Network, perfomed equally well and this actually surprised me a bit. The Neural Network score varies depending on the parameters passed into the classifier class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a77c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
